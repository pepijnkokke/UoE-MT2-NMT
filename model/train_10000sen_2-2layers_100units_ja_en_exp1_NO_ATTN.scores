Japanese English dataset configuration
vocab size, en=3713, fr=3949
--------------------------------------------------
Training progress will be logged in:
	model/train_10000sen_2-2layers_100units_ja_en_exp1_NO_ATTN.log
--------------------------------------------------
Trained model will be saved as:
	model/seq2seq_10000sen_2-2layers_100units_ja_en_exp1_NO_ATTN.model
--------------------------------------------------
Existing model not found!
--------------------------------------------------
epoch=1, iter=10000, loss=6.276028, mean loss=5.751620: 100%|██████████████████████████████████████████████████████████████████████████████| 10000/10000 [2:15:58<00:00,  1.22it/s]
--------------------------------------------------
precision  | 0.2335
recall     | 0.2344
f1         | 0.2340
--------------------------------------------------
computing perplexity
loss=5.973796: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:59<00:00,  5.47it/s]
--------------------------------------------------
dev perplexity | 38.6313
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
BLEU: 10.428
finished computing bleu ... 
--------------------------------------------------
epoch=2, iter=20000, loss=5.785933, mean loss=5.187471: 100%|██████████████████████████████████████████████████████████████████████████████| 10000/10000 [2:16:48<00:00,  1.21it/s]
--------------------------------------------------
precision  | 0.2422
recall     | 0.2548
f1         | 0.2483
--------------------------------------------------
computing perplexity
loss=5.554790: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:58<00:00,  5.70it/s]
--------------------------------------------------
dev perplexity | 35.5784
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=3, iter=30000, loss=5.476772, mean loss=4.872622: 100%|██████████████████████████████████████████████████████████████████████████████| 10000/10000 [2:16:30<00:00,  1.20it/s]
--------------------------------------------------
precision  | 0.2371
recall     | 0.2557
f1         | 0.2460
--------------------------------------------------
computing perplexity
loss=5.369571: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [02:01<00:00,  5.48it/s]
--------------------------------------------------
dev perplexity | 36.2345
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
BLEU: 13.475
finished computing bleu ... 
--------------------------------------------------