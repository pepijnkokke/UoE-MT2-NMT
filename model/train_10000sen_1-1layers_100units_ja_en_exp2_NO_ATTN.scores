Japanese English dataset configuration
vocab size, en=3713, fr=3949
--------------------------------------------------
Training progress will be logged in:
	model/train_10000sen_1-1layers_100units_ja_en_exp1_NO_ATTN.log
--------------------------------------------------
Trained model will be saved as:
	model/seq2seq_10000sen_1-1layers_100units_ja_en_exp1_NO_ATTN.model
--------------------------------------------------
Existing model not found!
--------------------------------------------------
epoch=1, iter=10000, loss=6.906671, mean loss=5.853061: 100%|██████████████████████████████████████████████████████████████████████████████| 10000/10000 [1:49:47<00:00,  1.57it/s]
--------------------------------------------------
precision  | 0.2061
recall     | 0.2300
f1         | 0.2174
--------------------------------------------------
computing perplexity
loss=6.414853: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:18<00:00,  7.92it/s]
--------------------------------------------------
dev perplexity | 42.8629
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
BLEU: 11.379
finished computing bleu ... 
--------------------------------------------------
epoch=2, iter=20000, loss=6.290832, mean loss=5.409569: 100%|██████████████████████████████████████████████████████████████████████████████| 10000/10000 [1:49:17<00:00,  1.59it/s]
--------------------------------------------------
precision  | 0.2263
recall     | 0.2478
f1         | 0.2365
--------------------------------------------------
computing perplexity
loss=6.103860: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:17<00:00,  7.69it/s]
--------------------------------------------------
dev perplexity | 38.0414
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=3, iter=30000, loss=6.435817, mean loss=5.234727: 100%|██████████████████████████████████████████████████████████████████████████████| 10000/10000 [1:50:06<00:00,  1.51it/s]
--------------------------------------------------
precision  | 0.2375
recall     | 0.2486
f1         | 0.2430
--------------------------------------------------
computing perplexity
loss=6.173522: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:16<00:00,  8.24it/s]
--------------------------------------------------
dev perplexity | 38.0865
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
BLEU: 13.008
finished computing bleu ... 
--------------------------------------------------
epoch=4, iter=40000, loss=6.089766, mean loss=5.115884: 100%|██████████████████████████████████████████████████████████████████████████████| 10000/10000 [1:51:52<00:00,  1.13it/s]
--------------------------------------------------
precision  | 0.2344
recall     | 0.2539
f1         | 0.2437
--------------------------------------------------
computing perplexity
loss=6.505529: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:14<00:00,  6.73it/s]
--------------------------------------------------
dev perplexity | 37.8191
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
--------------------------------------------------
epoch=5, iter=50000, loss=5.657694, mean loss=5.026426: 100%|██████████████████████████████████████████████████████████████████████████████| 10000/10000 [2:12:14<00:00,  1.56it/s]
--------------------------------------------------
precision  | 0.2256
recall     | 0.2587
f1         | 0.2411
--------------------------------------------------
computing perplexity
loss=6.034671: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:27<00:00,  6.96it/s]
--------------------------------------------------
dev perplexity | 38.6933
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
BLEU: 14.381
finished computing bleu ... 
--------------------------------------------------